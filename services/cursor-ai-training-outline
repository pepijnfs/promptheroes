- **Outline for a 2–3 Hour “Getting Started with Cursor AI” Training**
    
    ### 1. **Welcome & Agenda Overview** (5 minutes)
    
    - **Objectives**:
        - Introduce Cursor AI as a coding assistant leveraging LLMs.
        - Provide fundamentals of LLMs and best prompting practices.
        - Engage with live demos.
    
    ### 2. **Introduction to Large Language Models (LLMs)** (15–20 minutes)
    
    - **What Are LLMs?**
        - Brief history and evolution of transformer-based models.
        - Key differences between GPT-4, Claude 3.5, and Claude 3.7.
    - **Why They Matter for Developers**
        - Automating repetitive coding tasks.
        - Enhancing productivity, brainstorming, and code reviews.
    
    ### 3. **Prompting Best Practices** (20–25 minutes)
    
    - **Effective Prompt Structure**
        - “System” vs. “User” prompts; setting context and constraints.
        - Utilizing step-by-step reasoning prompts.
    - **Variations in GPT vs. Claude Models**
        - Similarities and differences in tone, creativity, and token handling.
        - Example prompts that work best for each model (e.g., clarifying instructions vs. open-ended brainstorming).
    - **Common Pitfalls**
        - Overly broad prompts leading to generic responses.
        - Under-specifying the task resulting in incomplete solutions.
    
    ### 4. **Overview of Cursor AI** (15 minutes)
    
    - **What Is Cursor AI?**
        - Explanation of how it integrates with GPT-4 and Claude.
        - Compatibility and typical use cases.
    - **Installation & Setup**
        - Quick steps for installing Cursor in a developer’s environment (e.g., VS Code-like workflow).
        - Configuration requirements (API keys, model selection).
    
    ### 5. **Hands-On with Cursor AI** (35–45 minutes)
    
    **(Live Demo & Group Interaction)**
    
    1. **Initial Project Setup**
        - Creating a new workspace / project in Cursor.
    2. **Generating Boilerplate Code**
        - Prompting Cursor for new files, templates, or boilerplate code.
    3. **Refactoring & Debugging**
        - Demonstration: “Ask Cursor to refactor a function with best practices.”
        - Debugging approach: “Identify issues in a snippet and have Cursor suggest fixes.”
    4. **Iterative Development**
        - Improving code clarity, adding docstrings, or comments via Cursor prompts.
    
    **(Encourage participants to follow along on their own machines if possible.)**
    
    ### 6. **Advanced Tips & Use Cases** (15–20 minutes)
    
    - **Prompt Engineering for Complex Tasks**
        - Working with multi-step coding tasks or advanced refactoring.
        - Chaining prompts to build larger solutions.
    - **Collaboration & Version Control**
        - How Cursor interacts with Git-based workflows.
        - Potential pitfalls when merging AI-generated code.
    - **Performance & Model Selection**
        - When to choose GPT-4 vs. Claude 3.5 or Claude 3.7 for efficiency or creativity.
    
    **Total Estimated Duration**: ~2–3 hours (adjust any section’s depth/time based on the audience’s engagement).
    
    **Key Takeaways**:
    
    - Introduction to LLM fundamentals and how they power AI coding tools like Cursor.
    - Practical understanding of best prompting techniques to maximize GPT-4 and Claude model outputs.
    - Live, hands-on familiarity with using Cursor AI for code generation, refactoring, and debugging.

[Chapter 1: Welcome & Agenda Overview](https://www.notion.so/Chapter-1-Welcome-Agenda-Overview-1ca0a8c52476801a9941ed8a2314cd17?pvs=21)

[Chapter 2: Introduction to Large Language Models](https://www.notion.so/Chapter-2-Introduction-to-Large-Language-Models-1ca0a8c5247680a3ade7c34e6a5d20f8?pvs=21)

[Chapter 3: Prompting Best Practices](https://www.notion.so/Chapter-3-Prompting-Best-Practices-1ca0a8c524768084a029c661e0c786dc?pvs=21)

[Chapter 4: Overview of Cursor AI](https://www.notion.so/Chapter-4-Overview-of-Cursor-AI-1ca0a8c5247680b88744d5460e0864cd?pvs=21)

[Chapter 5: Live Demo – Building a "To-Do List" App with Cursor AI](https://www.notion.so/Chapter-5-Live-Demo-Building-a-To-Do-List-App-with-Cursor-AI-1ca0a8c5247680f48374c062c06f16c4?pvs=21)

[Chapter 6: Advanced Tips & Comparisons](https://www.notion.so/Chapter-6-Advanced-Tips-Comparisons-1ca0a8c5247680a5998af9e5f36e5bde?pvs=21)

# Chapter 1: Welcome & Agenda Overview

Welcome to the **Getting Started with Cursor AI Workshop**. Over the next 2–3 hours, we'll explore how Cursor AI can enhance your productivity as a developer, providing practical knowledge on leveraging Large Language Models (LLMs) such as GPT-4 and Claude 3.5/3.7 directly in your development workflow.

## Objectives

By the end of this training, you will:

- Understand **what Cursor AI is** and how it integrates AI coding capabilities into your existing development environment.
- Grasp the **fundamentals of Large Language Models (LLMs)**, particularly transformer-based models like GPT-4 and Anthropic's Claude.
- Learn and apply **best prompting practices** to effectively interact with AI models, enhancing the quality and precision of responses.
- Gain hands-on experience by **building a simple To-Do List app** with real-time AI assistance using Python.
- Be aware of advanced prompting strategies, when to use different AI models, and how Cursor AI compares to alternative solutions such as GitHub Copilot and Windsurf.

## Workshop Agenda

### 1. **Introduction to Large Language Models (LLMs)**

*(~15–20 minutes presentation)*

- Brief history and overview of transformer-based models
- Differences among GPT-4, Claude 3.5, and Claude 3.7
- Relevance of LLMs to software development productivity

### 2. **Prompting Best Practices**

*(~20 minutes presentation & examples)*

- How to structure effective prompts for clarity and precision
- Key differences in prompting GPT vs. Claude models
- Common pitfalls: ambiguity, overly broad prompts, and how to avoid them

### 3. **Overview of Cursor AI**

*(~15 minutes presentation & setup instructions)*

- What Cursor AI is, and how it integrates GPT-4 and Claude models
- Real-world use cases and benefits
- Installation and basic configuration across Windows, macOS, and Linux
- Essential shortcuts and commands for efficient coding

### 4. **Live Demo: Building a To-Do List App**

*(~45–60 minutes interactive hands-on session)*

- Setting up a new Python project in Cursor
- Using AI prompts to generate boilerplate and core CRUD functionality
- Testing, debugging, and iterative development using Cursor
- Optional: implementing data persistence with JSON file storage

### 5. **Advanced Tips & Comparisons**

*(~15–20 minutes presentation)*

- Advanced prompting techniques for complex or multi-step tasks
- Choosing the appropriate AI model (GPT-4 vs. Claude 3.5/3.7) for specific scenarios
- Brief comparison of Cursor AI with alternatives: GitHub Copilot and Windsurf

### 6. **Q&A and Next Steps**

*(~10–15 minutes interactive session)*

- Addressing common questions and advanced usage scenarios
- Recommended resources: official documentation, community forums, and further reading
- Suggestions on integrating Cursor AI effectively into daily workflows

## Why This Matters: Productivity Gains from AI-assisted Development

The integration of AI tools such as Cursor AI can significantly enhance developer efficiency. Recent surveys show that developers using AI-powered coding tools experience productivity boosts of up to **30%**. Common improvements include:

- Faster code generation and completion
- Reduced time spent on debugging and refactoring repetitive code
- Easier exploration of unfamiliar libraries or frameworks through conversational assistance

Embracing these technologies allows you to focus more on complex problem-solving and innovation, making your development experience more rewarding and efficient.

## Example Use Case: What You’ll Achieve in Today’s Workshop

In the interactive demo, you'll build a basic To-Do List application step-by-step using Cursor AI and Python. Here's a brief preview of what the application will involve:

### Example: Python To-Do List Application Structure

```python
python
CopyEdit
tasks = []

def add_task(title):
    tasks.append({"title": title, "completed": False})

def list_tasks():
    for i, task in enumerate(tasks, start=1):
        status = "✓" if task["completed"] else "✗"
        print(f"{i}. [{status}] {task['title']}")

def complete_task(index):
    if 0 < index <= len(tasks):
        tasks[index - 1]["completed"] = True
    else:
        print("Invalid task index.")

def delete_task(index):
    if 0 < index <= len(tasks):
        tasks.pop(index - 1)
    else:
        print("Invalid task index.")

# Interactive command loop (simplified)
if __name__ == "__main__":
    while True:
        command = input("Enter a command (add/list/complete/delete/quit): ").strip().lower()
        if command == "add":
            title = input("Task title: ")
            add_task(title)
        elif command == "list":
            list_tasks()
        elif command == "complete":
            try:
                index = int(input("Task number to complete: "))
                complete_task(index)
            except ValueError:
                print("Please enter a valid number.")
        elif command == "delete":
            try:
                index = int(input("Task number to delete: "))
                delete_task(index)
            except ValueError:
                print("Please enter a valid number.")
        elif command == "quit":
            break
        else:
            print("Unknown command.")

```

This straightforward application will illustrate how you can leverage Cursor AI to streamline writing, testing, and improving code.

## Cross-platform Setup and Shortcuts

Throughout this workshop, all examples and instructions will include keyboard shortcuts for **Windows, macOS, and Linux**, ensuring ease of use regardless of your development environment. For example:

| Action | Windows/Linux Shortcut | macOS Shortcut |
| --- | --- | --- |
| Inline AI Edit | `Ctrl+K` | `Cmd+K` |
| Open AI Chat Sidebar | `Ctrl+L` | `Cmd+L` |
| Accept Inline Suggestion | `Tab` | `Tab` |
| Reject/Cancel Inline Suggestion | `Esc` | `Esc` |
| Open Command Palette | `Ctrl+Shift+P` | `Cmd+Shift+P` |
| Open Integrated Terminal | `Ctrl+`` | `Cmd+`` |

## Getting Ready: Installation Checklist

Before we dive into the next chapter, make sure you have Cursor AI installed and configured:

1. **Download** the Cursor AI installer for your operating system:
    - [Cursor AI Official Website](https://cursor.sh/)
2. **Install** Cursor following the provided instructions (straightforward installer for each OS).
3. **Setup**: Upon opening Cursor, provide your OpenAI and/or Anthropic API keys or choose Cursor's built-in cloud API option (Cursor Pro).

Now, let’s move on to Chapter 2, where we’ll start exploring the fundamentals of Large Language Models (LLMs).

# Chapter 2: Introduction to Large Language Models (LLMs)

## What Are Large Language Models (LLMs)?

Large Language Models (LLMs) are advanced artificial intelligence models trained on massive amounts of text data, capable of understanding context, generating human-like text, and performing complex tasks such as writing code, creating content, and answering detailed questions.

### Key Features of LLMs:

- Trained on extensive text corpora from books, articles, websites, and code repositories.
- Utilize deep learning techniques, particularly neural networks.
- Rely on probabilistic prediction to generate meaningful responses based on patterns identified during training.

## History and Basics of Transformer Models

The backbone technology behind modern LLMs is the **Transformer architecture**, introduced in 2017 by the seminal paper ["Attention Is All You Need"](https://arxiv.org/abs/1706.03762). Transformer models significantly improved language processing capabilities, enabling the development of sophisticated LLMs such as GPT and Claude.

### Key Innovations of Transformers:

- **Self-Attention Mechanism**: Enables models to consider relationships between all words simultaneously rather than sequentially, significantly enhancing contextual understanding.
- **Parallel Computation**: Transformers are efficient because they process input tokens simultaneously, allowing for better scalability and faster training.

## Evolution of Notable LLMs

Understanding the evolution of transformer-based models gives insight into current capabilities and potential:

| Year | Model | Organization | Key Innovation |
| --- | --- | --- | --- |
| 2018 | GPT (GPT-1) | OpenAI | First transformer-based generative language model |
| 2018 | BERT | Google | Bidirectional context understanding |
| 2019 | GPT-2 | OpenAI | Strong generative capabilities |
| 2020 | GPT-3 | OpenAI | Massive parameter size (175B) |
| 2022 | GPT-3.5 (ChatGPT) | OpenAI | Optimized for chat and conversational tasks |
| 2023 | GPT-4 | OpenAI | Advanced reasoning, multimodal inputs |
| 2023 | Claude 3.5, 3.7 (Sonnet) | Anthropic | Enhanced coding, large context (100K tokens) |

## Differences among GPT-4, Claude 3.5, and Claude 3.7

Understanding key differences among these models helps developers choose the appropriate LLM based on their project needs.

### GPT-4 (OpenAI):

- **Reasoning & Precision**: Excellent at step-by-step reasoning, logical consistency, and detailed instructions.
- **Context Window**: Typically supports around 8,000 tokens (up to 32,000 tokens with special versions).
- **Multimodal Capability**: Can process both text and images, enabling diverse use-cases beyond purely textual tasks.
- **Usage**: Ideal for complex problem-solving, strict formatting requirements, and precision-driven tasks.

### Claude 3.5 "Sonnet" (Anthropic):

- **Large Context**: Capable of handling up to 100,000 tokens, suitable for analyzing entire codebases or extensive documents in one prompt.
- **Coding Strengths**: Optimized for programming tasks, effectively generating consistent and accurate code.
- **Conversational Clarity**: Generally clear, explanatory, and conversational responses, often proactively suggesting improvements.
- **Usage**: Ideal for coding-heavy tasks, extensive document analysis, and tasks needing broad context.

### Claude 3.7 "Sonnet" (Anthropic):

- **Hybrid Reasoning Mode**: Includes an "extended thinking mode," allowing the model to take additional processing time for improved accuracy and reasoning.
- **Improved Intelligence**: Offers enhancements over Claude 3.5, particularly in complex reasoning, debugging, and high-quality code generation.
- **Flexibility**: Users can choose between faster, standard responses or slower, more accurate outputs based on task complexity.
- **Usage**: Best used for challenging coding tasks, deep reasoning requirements, and scenarios where precision matters significantly.

## Significance of LLMs for Developer Productivity

LLMs dramatically impact software development by automating repetitive tasks, improving code quality, and facilitating faster problem-solving. Their relevance spans several key development activities:

- **Code Generation**: Rapidly generate boilerplate code, complex functions, or entire modules from concise descriptions.
- **Debugging Assistance**: Interpret error messages, identify bugs, and propose potential solutions, significantly reducing debugging time.
- **Documentation & Comments**: Automatically write clear documentation, comments, and explain code behavior.
- **Code Refactoring**: Suggest efficient code refactors and best practices, improving maintainability and readability.

### Practical Example (Code Generation with GPT-4 or Claude):

Prompt example:

```
Write a Python function that checks if a given string is a palindrome.
```

Generated code example:

```python
def is_palindrome(s):
    # Clean the string by removing spaces and converting to lowercase
    cleaned_s = ''.join(char.lower() for char in s if char.isalnum())

    # Check if the cleaned string is equal to its reverse
    return cleaned_s == cleaned_s[::-1]

# Example usage
print(is_palindrome("Racecar"))  # Output: True
print(is_palindrome("Hello"))    # Output: False
```

## Key Takeaways for Developers

- **Context Matters**: Understanding each model's strengths allows developers to strategically choose the best tool for each job.
- **Productivity Boost**: Properly leveraging LLMs results in significant time savings and enables developers to focus on complex and creative tasks.
- **Continuous Learning**: The field of LLMs is rapidly evolving, and staying updated on new developments and best practices is crucial for maximizing their benefits.

# Chapter 3: Prompting Best Practices

## Introduction to Prompt Engineering

Effectively interacting with Large Language Models (LLMs) like GPT-4 and Claude 3.7 depends heavily on your ability to write clear, structured prompts. Prompt engineering involves crafting specific instructions that guide the AI towards precise and accurate responses, significantly improving output quality.

## Effective Prompt Structure

An effective prompt typically includes three key components:

- **Context**: Clearly states background information or assumptions.
- **Clarity**: Explicitly defines the exact task and desired outcome.
- **Constraints**: Provides boundaries or specific requirements to prevent ambiguous or irrelevant outputs.

### Good Prompt Example:

```
Context: You are a Python developer writing a function for data validation.
Task: Write a Python function named 'validate_email' that checks if a provided email address is valid. The function should use regex and return True if valid, False otherwise.
Constraints: Do not use external libraries beyond the Python standard library. Provide a brief comment explaining the regex pattern.
```

**Model Output:**

```python
import re

def validate_email(email):
    # Regex pattern to check standard email formatting: 'username@domain.extension'
    pattern = r'^[a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, email))

# Example usage
print(validate_email("user@example.com"))  # Output: True
print(validate_email("invalid-email"))     # Output: False
```

## Differences in Prompting GPT vs. Claude

GPT and Claude models have subtle but meaningful differences in their responses to prompting:

| Aspect | GPT-4 | Claude 3.5/3.7 |
| --- | --- | --- |
| **Response Detail** | Very detailed; step-by-step answers | Concise; clear explanations and summaries |
| **Context Handling** | Efficient for smaller, detailed prompts | Superior at large-context tasks (entire codebases, long docs) |
| **Conversational Tone** | Formal, structured, precise | Conversational, explanatory, collaborative |
| **Complex Instructions** | Excellent; clearly follows multi-step logic | Handles complex prompts well, excels in deep reasoning |

## Common Pitfalls and How to Avoid Them

### Pitfall 1: **Overly Broad or Ambiguous Prompts**

- **Problem:** Results in generic, less useful outputs.
- **Solution:** Clearly specify tasks and outcomes. Always provide explicit context and constraints.

**Ambiguous Prompt Example:**

```

Write a validation function.
```

**Clear Prompt Improvement:**

```
Write a JavaScript function named 'isValidPhoneNumber' that validates phone numbers in the format (123) 456-7890. Return true if valid, false otherwise.
```

### Pitfall 2: **Insufficient Context**

- **Problem:** LLMs generate irrelevant or incomplete outputs.
- **Solution:** Provide background or context that clearly frames the task.

**Insufficient Context Example:**

```
Fix this bug in my code.
```

**Better Contextualized Prompt:**

```
Context: I'm using Python to parse dates from CSV data but getting a ValueError.
Task: Provide a corrected version of the following code snippet. The goal is to parse dates formatted as 'dd/mm/yyyy'.

Current Code:
dates = ['25/12/2024', '31/01/2025']
parsed_dates = [datetime.strptime(date, '%Y-%m-%d') for date in dates]

Constraints: Keep solution concise, fix only what's necessary.
```

### Pitfall 3: **No Constraints Provided**

- **Problem:** The LLM generates overly complicated or inappropriate solutions.
- **Solution:** Set clear boundaries to guide responses toward relevant and acceptable solutions.

**Without Constraints:**

```
Generate a database schema for a blog.
```

**With Clear Constraints:**

```
Generate a concise PostgreSQL database schema for a blog. Include only tables for 'Posts', 'Comments', and 'Users'. Each table should have primary keys, relevant fields, and appropriate foreign key relationships. Keep it simple, avoid additional complexity.
```

## Interactive Prompting Exercise (5 min)

To reinforce these best practices, try writing your own prompt using the guidelines above:

- Clearly outline the **context** of your problem.
- Explicitly state the **task** you want the model to solve.
- Include clear **constraints** to narrow down the output.

**Example Exercise Prompt:**

```
Context: You're building a React app that fetches and displays user data from an API.
Task: Write a React component named 'UserProfile' that fetches user data from '/api/users/1' using the fetch API. Display user's name, email, and phone number once data is loaded.
Constraints: Use functional components with hooks. Include basic error handling.
```

## Summary: Key Takeaways for Prompt Engineering

- Always **provide clear context** to ensure the model understands the background.
- Use **explicit tasks** to precisely guide the model’s outputs.
- Clearly state **constraints** to avoid overly broad or irrelevant responses.
- Be aware of differences between models (GPT vs Claude) to optimize your prompts.

Prompt engineering is foundational to effectively leveraging Cursor AI, enabling you to unlock its full potential and enhance your coding workflow.

In the next chapter, you'll learn exactly how to set up and start coding interactively with Cursor AI.

# Chapter 4: Overview of Cursor AI

## Introduction to Cursor AI

Cursor AI is an advanced, AI-driven integrated development environment (IDE) designed specifically to integrate powerful Large Language Models (LLMs) like GPT-4 and Claude directly into your coding workflow. Accessible at [cursor.com](https://cursor.com/), Cursor significantly enhances developer productivity by enabling intuitive code generation, debugging assistance, refactoring suggestions, and seamless interaction with your codebase.

## How Cursor AI Integrates with GPT-4 and Claude

Cursor integrates directly with state-of-the-art LLM APIs, primarily OpenAI’s GPT-4 and Anthropic’s Claude 3.5/3.7, providing the following benefits:

- **Context-Aware Code Generation:** Instantly generate accurate, relevant code snippets based on context.
- **Interactive Debugging and Explanations:** Receive detailed insights and explanations of existing code or errors.
- **Smart, Contextual Refactoring:** Efficiently refactor and optimize code through AI-driven recommendations.
- **Multi-file and Codebase Awareness:** Particularly strong with Claude, handling large contexts (up to 100k tokens), allowing effective multi-file edits and codebase-level understanding.

Cursor’s integration workflow is straightforward:

1. You write or select code in Cursor’s editor.
2. Activate Cursor’s AI using inline shortcuts or the conversational AI sidebar.
3. The AI responds with actionable suggestions, edits, or comprehensive explanations.

## Cursor AI Modes: Agent, Ask, and Edit

Cursor AI provides three distinct interaction modes designed for various coding tasks, allowing developers flexibility and control over AI interaction.

### 1. Agent Mode

**Agent Mode** is Cursor’s most advanced, fully-integrated setting, enabling Cursor to autonomously perform a variety of coding tasks. The Agent can:

- Generate complete functions or components from simple, natural-language descriptions.
- Execute multi-file edits intelligently and consistently.
- Automatically run terminal commands (e.g., installing dependencies or running tests) directly within Cursor.

Agent Mode is ideal for developers who want rapid, AI-driven completion of complex or multi-step tasks.

### 2. Ask Mode

**Ask Mode** acts as an intelligent coding assistant, offering interactive dialogue without directly modifying your codebase. Use Ask Mode to:

- Obtain detailed explanations of specific code segments or functions.
- Clarify concepts, syntax, or unfamiliar code patterns.
- Request best-practice recommendations and general coding advice.

Ask Mode is particularly suited for learning, exploring, troubleshooting, and understanding existing code deeply.

### 3. Edit Mode

**Edit Mode** provides direct, inline code modifications guided by user instructions. This mode allows you to:

- Select code segments and describe desired changes.
- Receive immediate, precise, and context-aware edits directly within your existing files.
- Generate or insert new code snippets within your codebase context.

Edit Mode gives developers hands-on control, ideal for precise adjustments, refactoring, and incremental development.

## Distinction between Agent, Ask, and Edit Modes

Understanding the practical distinctions among Cursor’s AI modes enables you to choose the appropriate level of AI engagement for your tasks:

| Mode | Primary Use-case | AI Engagement Level |
| --- | --- | --- |
| **Agent** | Autonomous multi-step tasks, large-scale edits | High (fully autonomous) |
| **Ask** | Learning, explanation, troubleshooting | Medium (interactive support) |
| **Edit** | Precise edits, incremental code adjustments | High (guided direct edits) |

## Installation and Setup

Setting up Cursor AI across your development environment (Windows, macOS, Linux) is straightforward:

**Step-by-step Installation:**

1. **Download Cursor AI:**
    
    Visit [cursor.com](https://cursor.com/) and select the version compatible with your operating system.
    
2. **Installation Process:**
    - **Windows/Linux:** Run the downloaded installer and follow on-screen instructions.
    - **macOS:** Drag Cursor to your Applications folder and launch the application.
3. **Initial Configuration:**
    - Open Cursor and sign in or create an account.
    - Link your OpenAI or Anthropic API keys for direct LLM integration, or opt for Cursor’s built-in API via Cursor Pro.

## Essential Cursor AI Shortcuts

Streamline your coding process with Cursor’s intuitive shortcuts:

| Action | Windows/Linux Shortcut | macOS Shortcut |
| --- | --- | --- |
| Trigger Inline AI Edit (Edit Mode) | `Ctrl+K` | `Cmd+K` |
| Open AI Chat Sidebar (Agent/Ask Mode) | `Ctrl+L` | `Cmd+L` |
| Accept Inline Suggestion | `Tab` | `Tab` |
| Reject/Cancel Inline Suggestion | `Esc` | `Esc` |
| Open Command Palette | `Ctrl+Shift+P` | `Cmd+Shift+P` |
| Open Integrated Terminal | `Ctrl+`` | `Cmd+`` |

## Practical Usage Example with Cursor AI (Python)

### Scenario:

Quickly create a Python function for fetching JSON data from an API endpoint

**Prompt Example (Using Edit or Agent Mode):**

```
Write a Python function named 'fetch_json' that fetches JSON data from a given URL using requests. Include error handling.
```

**Cursor-generated Python Code:**

```python
import requests

def fetch_json(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Handle HTTP errors
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Error fetching data: {e}")
        return None

# Usage
data = fetch_json('https://api.example.com/data')
if data:
    print(data)
```

## Customizing Cursor AI Settings

Customize Cursor to align with your workflow and preferences:

- **Model Selection:**
    
    Switch between GPT-4 (ideal for precise, detailed reasoning) and Claude 3.7 (excellent for large codebases and extended context).
    
- **Contextual Settings:**
    
    Adjust file inclusion or exclusion for Cursor’s AI, optimizing performance and accuracy of suggestions.
    
- **API Management:**
    
    Manage API keys directly in Cursor settings for seamless integration with OpenAI or Anthropic APIs.
    

## Productivity Tips and Best Practices

- **Incremental Prompts:**
    
    Break complex coding tasks into smaller, clear prompts for improved precision and effectiveness.
    
- **Iterative Approach:**
    
    Use Cursor AI repeatedly to iteratively refine and enhance your codebase incrementally.
    
- **Leveraging Contextual Awareness:**
    
    Organize your project files clearly, ensuring Cursor can fully utilize its context-awareness capabilities.
    
- **Continuous Interaction:**
    
    Regularly engage with Cursor’s conversational sidebar for clarification, debugging assistance, or quality assurance.
    

## Common Issues and Troubleshooting

- **Generic or Imprecise Suggestions:**
    
    Improve prompt specificity; clearly outline context, tasks, and constraints.
    
- **Slow Responses (extended Claude mode):**
    
    Choose standard Claude mode or GPT-4 for quicker responses on simpler tasks.
    
- **Project Files Not Recognized:**
    
    Refresh or verify paths in Cursor’s project settings to ensure proper indexing.
    

## Chapter Recap

In summary:

- Cursor AI deeply integrates advanced LLMs (GPT-4 and Claude) into your development environment at [cursor.com](https://cursor.com/).
- Three interaction modes (Agent, Ask, Edit) offer tailored AI assistance levels for varying coding scenarios.
- Installation and configuration are straightforward across all major operating systems.
- Effective use of Cursor shortcuts, best practices, and troubleshooting ensures optimal productivity.

With these foundational skills, you’re now prepared to actively apply Cursor AI capabilities in the upcoming interactive coding exercise, where you'll build a practical To-Do List application from scratch.

# Chapter 5: Live Demo – Building a "To-Do List" App with Cursor AI

## Introduction to the Interactive Demo

Now it's your turn! In this practical exercise, you'll apply your newly acquired skills by building a fully functional **To-Do List application** entirely within Cursor AI. The session revolves around strategic prompting, leveraging Cursor’s powerful integration with Claude 3.7 Sonnet, and effectively applying prompt engineering practices.

## Demo Objectives

By the end of this demo, you'll confidently:

- Provide clear, structured context early on to maximize AI-generated results.
- Use effective prompting strategies tailored specifically for Claude 3.7 Sonnet.
- Iteratively develop, debug, and refine your application.
- Enhance your application with basic UI improvements.

## Step 1: Creating the Right Context for Claude 3.7 Sonnet

Context is key to leveraging Claude 3.7 Sonnet effectively. Your first step sets the foundation for your entire project.

**Open Cursor AI** (from [cursor.com](https://cursor.com/)) and immediately activate the AI sidebar (`Ctrl+L` on Windows/Linux, `Cmd+L` on macOS).

### Prompt Claude 3.7 clearly and directly, requesting a structured development outline:

```
You are a pro developer with over 10+ years experience building CRUD-style applications. Your goal is to assist me in building a command-line "To-Do List" application using Python. Create a detailed development outline in markdown format, clearly dividing the project into logical steps:

- Include setting up the virtual environment and project structure
- Provide clear steps for implementing CRUD functionality
- Suggest steps for interactive testing and error handling
- Recommend a final step for integrating a simple terminal UI enhancement using the Python "Rich" library

Keep the outline clear and concise.
```

**Claude’s structured markdown outline** will become your project roadmap. You will refer to this outline throughout your development process to track progress and maintain clarity.

## How to Get the Best Out of Claude 3.7 Sonnet

Claude 3.7 Sonnet is powerful, but how you use it determines your project's success. Follow these best practices to ensure excellent results every time:

### 1. Be Clear and Direct

- The more specific your prompt, the better the response.
- Example:
    - Instead of:
        
        `Tell me about AI`
        
    - Try:
        
        `Explain how Claude 3.7 Sonnet handles reasoning compared to other AI models.`
        

### 2. Use Extended Thinking Mode for Complex Tasks

- Quick mode for straightforward questions and rapid code suggestions.
- Extended mode for deep reasoning, code refactoring, debugging, and complex logic.
- Extended mode is recommended for this demo.

### 3. Break Big Tasks into Smaller Steps

- Rather than one long prompt, divide tasks into clear, sequential prompts.
- Example breakdown:
    - **Step 1**: Generate CRUD functions.
    - **Step 2**: Implement error handling and input validation.
    - **Step 3**: Refactor code into maintainable structure.

### 4. Use Claude for Efficient Development

- Leverage Claude’s coding capabilities for debugging, testing, and iterative improvements.
- Efficiently generate code snippets, troubleshoot errors, and quickly enhance your app.

**The secret to maximizing Claude 3.7 Sonnet’s capabilities is providing structured, detailed context from the start.**

## Step 2: Generating the App’s Basic Functionality

Follow the structured outline generated by Claude. Prompt clearly and directly for each step (CRUD functionality, memory storage, etc.).

**Example prompt:**

```
Implement CRUD methods based on the provided outline. Ensure proper handling of task management logic and basic error checking.
```

## Step 3: Interactive Testing within Cursor

Use Cursor’s terminal and Claude’s guidance to run interactive tests directly from your workspace.

**Prompt Claude:**

```
Guide me through interactively testing all CRUD functionalities of the To-Do List app within Cursor’s integrated terminal.
```

Follow the testing scenarios Claude provides.

## Step 4: Iterative Debugging and Refinement (Ask Mode)

Prompt Claude in Ask Mode clearly, breaking down issues or enhancements into smaller, manageable questions:

**Example prompt:**

```
Suggest improvements to gracefully handle invalid inputs, such as empty strings or incorrect data types provided by users.
```

Implement improvements suggested by Claude directly using Edit Mode.

## Step 5: Refactoring the App into a Class Structure

Prompt Claude to refactor your codebase into a maintainable and clear class-based structure, referencing your outline:

```
Refactor the entire application into the class-based structure outlined previously, encapsulating tasks and related methods logically.
```

## Step 6: Adding Terminal UI Enhancements Using Rich

Finish with a visually appealing enhancement by integrating the Python "Rich" library. Prompt Claude explicitly referencing your original outline:

```
Integrate the 'Rich' Python library into our To-Do List app to provide enhanced terminal UI formatting, colors, and improved readability, as outlined previously.
```

Let Claude generate and integrate this enhancement directly into your project.

## Demo Recap and Key Takeaways

Throughout this interactive demo, you successfully:

- Provided comprehensive context upfront, significantly enhancing AI response quality.
- Applied structured, clear prompting strategies to leverage Claude 3.7 Sonnet effectively.
- Iteratively refined your application using Claude’s powerful debugging and refactoring features.
- Seamlessly integrated frontend enhancements to improve user experience quickly.

By establishing detailed, clear contexts early on, you've experienced firsthand how Claude and Cursor can rapidly transform your ideas into practical, polished applications.

In the next chapter, you'll discover advanced Cursor AI tips, explore selecting between different LLMs (GPT vs. Claude), and compare Cursor AI to alternatives like GitHub Copilot and Windsurf.

# Chapter 6: Advanced Tips & Comparisons

## Introduction to Advanced Tips & Comparisons

By now, you’ve seen how powerful Cursor AI can be when combined with thoughtful prompting and a clear coding goal. In this chapter, we’ll go one step further—sharing advanced tips to sharpen your prompting strategy, showing you when to use GPT-4 versus Claude 3.7 Sonnet, and giving you a realistic, experience-backed comparison between Cursor AI and alternative tools like GitHub Copilot and Windsurf.

The goal? Help you understand not just how Cursor works, but why it might be the best fit for your daily workflow—and when it might not.

## Advanced Prompting Tips for Cursor

### 1. **Use Cursor Like a Pair Programmer**

Cursor’s strength lies in how naturally you can "talk" to it. Instead of treating it like a search engine, use natural language to describe what you want, then refine together.

**Example:**

```
I’m working on a FastAPI project and want to create an endpoint for submitting form data. It should validate the fields and return a JSON response.
```

Then iterate:

```
Add error handling.
Now generate tests for this endpoint.
```

This conversational, layered prompting works especially well in Ask and Edit modes.

### 2. **Use Agent Mode for Project-Wide Tasks**

Agent mode shines when you need broad actions across multiple files—like refactoring a function that's repeated everywhere, or upgrading a naming convention throughout your codebase.

**Example:**

```
Find all functions named fetch_data and rename them to get_data, updating imports and usages across the project.
```

This is where Cursor pulls ahead of most AI coding tools: it understands your full codebase and can act on it.

### 3. **Combine Ask, Edit, and Agent Modes Effectively**

Each mode in Cursor has a purpose:

- **Ask Mode**: Best for questions, documentation, and clarifying code you don’t understand.
- **Edit Mode**: Perfect for scoped refactors or rewriting a specific block.
- **Agent Mode**: Use it when the task touches multiple files, or when you want the AI to take initiative and suggest solutions.

A strong workflow balances all three.

## GPT-4 vs Claude 3.7: When to Use What

Both models are powerful—but they behave differently, and knowing when to switch is key.

### Use **Claude 3.7 Sonnet** when:

- You're working with **large projects** that require deep context (Claude supports up to 100k tokens).
- You want a **collaborative tone** that asks clarifying questions or offers trade-offs.
- You need **refactoring or multi-file analysis**—Claude is excellent at stepping back and "seeing the big picture."

### Use **GPT-4** when:

- You need **precise logic**, **step-by-step reasoning**, or strict formatting (e.g., JSON, regex).
- You’re working on **algorithms**, backend-heavy logic, or anything requiring **tight, correct-by-construction outputs**.
- You're generating **concise, single-file completions**—like writing a component from scratch.

**Cursor lets you switch models easily**, so try both and see what fits your coding task best.

## Cursor AI vs GitHub Copilot vs Windsurf

Now let’s talk about the other tools developers might have heard of—or used.

### GitHub Copilot

Copilot is the “autocomplete on steroids” that many developers know from VS Code. It excels at **inline code completions**—it’s fast, simple, and very easy to adopt for small-to-medium tasks.

**When it’s great:**

- You know what you want to write, and just want it filled in faster.
- You’re working on a familiar codebase and don’t need AI to "think with you".

**Where it falls short:**

- **Limited context awareness**—Copilot doesn’t truly understand your whole project.
- **No chat or agent-style interface**—you can’t ask questions or get high-level architectural suggestions.

In short: Copilot is great for speeding up routine coding. Cursor, by contrast, is about **collaborative building** and **deep codebase integration**.

### Windsurf

Windsurf is a newer IDE based on VS Code that integrates AI through custom workflows. It offers a unique approach with "Cascade Memories" (to persist context across sessions) and a focus on collaborative prompts.

**When it’s interesting:**

- You want persistent context between sessions.
- You value experimental interfaces and work on projects that benefit from AI memory.

**Where it lacks behind Cursor:**

- Cursor is **more robust for full-scale project understanding**.
- Agent mode in Cursor offers better multi-file execution and smarter auto-edits.
- Cursor’s **UI and model-switching workflow is faster and cleaner**.

Windsurf may appeal to developers who want to tinker with AI workflows—but Cursor is the more **pragmatic, production-ready** environment for getting real work done fast.

## So… Why Cursor?

If you:

- Work on multi-file projects
- Need both answers and execution
- Want full control over which model you use
- Prefer a UI that feels like an IDE, not a chatbot

**Cursor is likely your best bet.**

It’s the first AI development tool that truly understands what software engineers need: less fluff, more clarity, and fewer manual tasks.

## Chapter Recap

- Cursor’s strength lies in the balance of **Agent, Ask, and Edit modes**.
- Claude 3.7 Sonnet and GPT-4 serve different roles—learn when to use each.
- Compared to Copilot and Windsurf, Cursor offers **deeper project understanding**, **better multi-file editing**, and **a smoother AI-first workflow**.